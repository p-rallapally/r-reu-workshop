---
output:
  html_document:
    df_print: paged
    code_download: TRUE
    toc: true
    toc_depth: 1
editor_options:
  chunk_output_type: console
---

# Let's recap Day 2

Start by setting up the working directory. Then, read the `SAFI_clean` file as shown below:

```{r}
safi <- read.csv("data/SAFI_clean.csv",  na = c("", "NULL", "NA"))  
```

-   What are the names of the variables in the data (the columns)? You can see variable descriptions at: <http://www.datacarpentry.org/socialsci-workshop/data/>

-   How many observations in the data?

-   Open the data frame in the viewer

-   What are the types of the variables?

-   Make a table of respondent_wall_type to see how many observations for each. What do you notice?

-   Select just village and no_membrs columns (the latter is number of family members)

-   Print just the first row of data

-   Drop the instanceID column so it's no longer in the data frame

-   Select the column respondent_wall_type for just the rows where the village is God

-   Select rows where no_membrs is between 2 and 5

-   Load the ggplot2 package into your workspace and plot a graph to see if there is a relationship between no_membrs and rooms.

-   Add theme_classic and appropriate x,y and title labels to your plot

-   Color the data-points in the plot according to village

# Setup

This session covers some useful functions and gives examples of how to accomplish some common data tasks in R.

Reading in the policing data:

```{r}
evp <- read.csv("data/ev_police_jan.csv")
```

Note: Evanston police data comes from the [Stanford Open Policing Project](https://openpolicing.stanford.edu/data/). This is a small subset of data: just January 2017.

And we'll use the penguins data for some exercises too

```{r}
library(palmerpenguins)
```

# Useful functions

## ifelse

`ifelse()` allows you to change the values of a vector based on a conditional test. It's useful for recoding data, and you can use it in situations where you don't want to change the underlying data.

The format is:

```{r, eval=FALSE}
ifelse(test_condition, value_if_true, value_if_false)
```

where the test condition is usually some comparison or operation on a vector - anything that results in TRUE or FALSE values

```{r}
x <- c(-1, 2, 3, -5, 3, NA, -4, 6)
x >= 0

ifelse(x >= 0, x, 0)  # replace negative values with 0, leave others alone

ifelse(is.na(x), 0, x)  # replace missing values with 0, leave others alone

ifelse(x %% 2 == 0, "even", "odd")  ## remainder of dividing x by 2 is 0 
```

There's also the useful `replace_na()` function in the tidyr package and `na_if()` in dplyr.

## EXERCISE

Where the value in the vector below is positive, take the square root. Where it is negative, substitute in `NA`.

```{r}
y <- c(4, -1, 3, 6, -7, 10, 20)
```

## %in%

`%in%` returns TRUE if the value on the left is in the vector on the right, FALSE otherwise. Unlike `==`, if the value on the left is `NA`, it will return FALSE unless `NA` is also in the vector on the right:

```{r}
x <- c(-1, 2, 3, -5, 3, NA, -4, 6)
x %in% c(1, 2, 3)
x == 1 | x == 2 | x == 3
```

```{r}
state.name  # built-in vector in R

ifelse(state.name %in% c("Alaska", "Hawaii"), NA, state.name)
```

## EXERCISE

Select the rows from the `evp` data where the vehicle make is one of FIAT, DATS, GEO, JAGU, or PEUG

```{r}

```

## paste

The `paste()` function is used to join pieces of text:

```{r}
paste("John", "Oliver")
```

The default separator between the strings is a space, but you can change it:

```{r}
paste("John", "Oliver", sep="---")
```

But, I frequently want to join strings with no space between them:

```{r}
paste("John", "Oliver", sep="")
```

There's a shortcut for this:

```{r}
paste0("John", "Oliver")
```

## EXERCISE

`state.abb` has two-letter abbreviations for US states. `state.region` has the region for each US state. Use `paste()` to join the info from these two vectors together, so the output has entries that look like:

```         
"AL: South"         "AK: West"          "AZ: West"          "AR: South"  ...
```

```{r}

```

## seq

`seq()` is used to generate sequences of numbers. You can specify the interval between values or how many values you want.

```{r}
seq(from=1, to=10, by=2)
```

Note that the sequence output will only have values that are \<= the "to" value.

```{r}
seq(0, 10, length.out=4)
```

```{r}
seq(0, 1, .1)
```

## EXERCISE

Use the `seq()` function to select every 5th row from `state.x77` (it's a matrix built in to R - you can index it like a data frame).

Things you need to figure out: how do you know what the sequence should go to? How do you use the result of seq() to then select the rows?

```{r}

```

# Factors

Factors are variables with text labels, but the set of values (called levels) that are allowed for the variable is limited, and the values optionally can have a specific order to them.

## Why Do I Need Factors?

Let's look at what happens with the days of the week if they are NOT a factor -- just character (text) data instead:

```{r}
library(lubridate)
evp$Date <- ymd(evp$date)  # did this in the exercise above
evp$dow <- as.character(wday(evp$Date, label=TRUE))  # as.character makes it not a factor - just text data
table(evp$dow)
```

The days are in alphabetical order, not day of the week order!

Or, let's make a plot of the reported race of the people stopped:

```{r, fig.width=5, fig.height=3}
library(ggplot2)
ggplot(evp, aes(x=subject_race)) +
  geom_bar() + theme_classic()
```

This is OK, but ideally the categories of a bar chart would either be in a meaningful order, or ordered by their frequency.

## Make a Factor

In both cases above, the character data is converted into a factor in the process of making a table or the plot. If we don't like the default ordering, we can control it by explicitly making the variable a factor ourselves and setting the levels.

The default order is alphabetical order, which is dependent on the locale of your computer (language and location settings).

```{r}
evp$subject_race <- factor(evp$subject_race, 
                           levels=c("white", "black", "hispanic", "asian/pacific islander", "other"))
head(evp$subject_race)
table(evp$subject_race)
```

Here, we specified the levels in order, so they will appear that way. But we didn't say that any category is greater than or less than another -- there isn't an inherit order to the categories, even though we did set the order that they will display in.

There aren't many cases where you're likely to do operations on a factor and actually need R to know which category is greater than another, but you can indicate that the factor is ordered if needed (ordered categorical data instead of just categorical data). Answers to scales from surveys is one case where ordered factors can be useful.

```{r}
answers <- c("Very unhappy", "Somewhat unhappy", "Somewhat happy", "Very happy", 
             "Somewhat unhappy", "Somewhat happy", "Somewhat unhappy", "Somewhat happy",
             "Very happy", "Very unhappy", "Very happy", "Very happy")
answers <- factor(answers, 
                  levels = c("Very unhappy", "Somewhat unhappy", "Somewhat happy", "Very happy"),
                  ordered = TRUE)
answers
```

You can see here that the levels are printed with less than signs `<` indicating a formal ordering that can be used in boolean comparisons.

## EXERCISE

Convert the vector below to a factor. Set the levels in an intentional order.

```{r}
directions <- c("east", "west", "east", "south", "north", "north", "west", "north", "east")

```

# Tidyverse (dplyr)

```{r, eval=TRUE}
library(tidyverse)
library(dplyr)
```

The data is from the [Stanford Open Policing Project](https://openpolicing.stanford.edu/data/) and includes vehicle stops by the Evanston police in 2017. We're reading the data in from a URL directly.

```{r, eval=TRUE}
police <- read_csv("data/ev_police.csv", col_types=c( "location"="c"))
```

# dplyr

dplyr is at the core of the tidyverse. It is for working with data frames. It contains six main functions, each a verb, of actions you frequently take with a data frame. We're covering 3 of those functions today (select, filter, mutate), and 3 more next session (group_by, summarize, arrange).

Each of these functions takes a data frame as the first input. Within the function call, we can refer to the column names without quotes and without \$ notation.

# Select: Choose Columns

The `select()` function lets us choose which columns (or variables) we want to keep in our data.

First, let's remember what the column names are:

```{r}
names(police)
```

The data frame is the first input, and the name of the column is the second. We do not have to put quotes around the column name.

```{r}
select(police, subject_race)
```

If we want to select additional columns, we can just list the column names as additional inputs, each column name separated by commas:

```{r}
select(police, subject_race, outcome)
```

As with `[]` indexing, columns will be returned in the order specified:

```{r}
select(police, subject_sex, subject_race, date)
```

We could also use the column index number if we wanted to instead. We don't need to put the values in `c()` like we would with `[]` (but we could).

```{r}
select(police, 1, 4, 10)
```

The columns will be ordered in the order we specify them.

```{r}
select(police, outcome, date)
```

## Ranges

There are a number of select helper functions and special syntax options that allow us to choose multiple columns.

First, we can use : for range, but with names in addition to numbers:

```{r}
select(police, raw_DriverRace:raw_ResultOfStop)
```

We can select the rightmost columns with `last_col()`:

```{r}
select(police, last_col())
```

Last 4 columns (the input to the function is the offset \# of columns from the right edge):

```{r}
select(police, 0:last_col(3))
```

## Excluding columns

We can also say which columns we don't want by putting a `-` in front of the name:

```{r}
select(police, -raw_row_number, -subject_age)
```

When using negated `-` column names, if we start with negations, it will include all other columns, even if we try to specify some:

```{r}
select(police, -raw_row_number, -subject_age, time:outcome)
```

To both specify the columns wanted and exclude some that would otherwise be selected, the exclusions need to come at the end:

```{r}
select(police, location:type, -department_id)
```

## Reordering and renaming

We've already seen that columns will appear in the result in the order that we list the names.

The `everything()` helper function can be useful if you want to pull a few columns over to the left so that they are the ones that show first when you look at the data:

```{r}
select(police, outcome, everything())
```

Each column only gets included once, in the position that it first appears. So "outcome" becomes the leftmost column above and no longer appears in it's original spot.

We can also rename columns while using `select()`. The syntax is `new_name = old_name`.

```{r}
select(police, raw_id=raw_row_number, date, time)
```

or we can use `rename()` to only rename, without affecting which columns are included or their order (all of the columns are kept in the same order):

```{r}
rename(police, raw_id=raw_row_number)
```

Remember, this doesn't change police because we didn't save the result. So far, we've just been printing the copy of the data frame that is returned by the function. If we want to change our data frame, we'd need to save the result back to the `police` object.

```{r}
police <- rename(police, raw_id=raw_row_number)
```

### EXERCISE

Remember: run the cells above to load tidyverse and import the data.

Using `select` and/or `rename` as needed:

-   Rename subject_age to age, subject_race to race, and subject_sex to sex, but keep the columns in their original order
-   Exclude the department_id and department_name columns

```{r}

```

## Matching names

We can also select by matching patterns in the names of the columns. The patterns to match are in quotes because they aren't column names -- just character data.

```{r}
select(police, starts_with("contraband"))
```

```{r}
select(police, ends_with("issued"))
```

```{r}
select(police, contains("vehicle"))
```

We can also put a `-` in front of these helper functions to exclude columns:

```{r}
select(police, -contains("subject"))
```

And there are even more [select helper functions](https://tidyselect.r-lib.org/reference/select_helpers.html).

### EXERCISE

Use `select()` to get a copy of `police` without the columns that start with "raw".

```{r}

```

Hint: If you mess up your `police` dataset, re-run the cell near the top of the file under the Data header and read the data in again fresh.

## Selecting with Vectors or Functions

What if we have the names of the columns we want to select in a vector already? For example:

```{r}
analysis_vars <- c("search_basis", "reason_for_stop")
```

Perhaps we built this vector programatically (we wrote code to determine the values, instead of typing them ourselves), so we can't just rewrite it to:

```{r}
select(police, search_basis, reason_for_stop)
```

If we just give the vector to `select`, it looks like we expect "analysis_vars" to be a column name in police. We get a warning:

```{r}
select(police, analysis_vars)
```

This warning tells us what we should do instead, which is use `all_of`:

```{r}
select(police, all_of(analysis_vars))
```

This makes it clearer that "analysis_vars" isn't the name of a column in police.

What if we want to select columns of a certain type -- for example, only the numeric columns?

```{r}
select(police, where(is.numeric))
```

`is.numeric` is the name of a function. We just use the name without `()`. This function is applied to each column, and if it returns TRUE, then the column is selected. Like above with using a vector, we wrap the function we want to use in `where` to make it clear that we're using a function, not looking for a column named "is.numeric").

`where` can be used with any function that returns a *single* TRUE or FALSE value for each column.

# Filter: Choose Rows

The `filter()` function lets us choose which rows of data to keep by writing expressions that return TRUE or FALSE for every row in the data frame. Recall from last session:

```{r}
filter(police, date == "2017-01-02")
```

We can do complex conditions as we could do with `[]`

```{r}
filter(police, subject_race == "hispanic" & subject_sex == "female")
```

If we include multiple comma-separated conditions, they are joined with `&` and. So this following is equivalent to the above.

```{r}
filter(police, subject_race == "hispanic", subject_sex == "female")
```

### EXERCISE

1.  Filter `police` to choose the rows where location is 60201 or 60202
2.  Filter `police` to choose the rows where location is 60201 or 60202 and subject_sex is "male"

Hints:

-   The "or" operator is `|`; the "and" operator is `&`

```{r}

```

## Including Variable Transformations

When filtering, we can include transformations of variables in our expressions. To see this, we'll use the built-in `mtcars` dataset, which, unlike the `police` data, has some numeric variables.

Here's what `mtcars` looks like:

```{r}
mtcars
```

Now, let's filter to see which cars have above average mpg:

```{r}
filter(mtcars, mpg > mean(mpg))
```

Or which car has the most horsepower (hp):

```{r}
filter(mtcars, hp == max(hp))
```

### EXERCISE

Using `mtcars`, find the car with the minimum (`min`) displacement (disp) value:

```{r}

```

# Slice

Unlike `select()`, we can't use row numbers to index which rows we want with filter. This gives an error:

```{r}
filter(mtcars, 10)
```

If we did need to use the row index (row number) to select which rows we want, we can use the `slice()` function.

```{r}
slice(mtcars, 10)
```

```{r}
slice(mtcars, 10:15)
```

We don't usually use `slice()` in this way when working with dplyr. This is because we ideally want to be working with well-structured data, where we can reorder the rows without losing information. If reordering the rows in the dataset would result in a loss of information (it would mess up your data), then the dataset is missing an important variable -- maybe just a sequence index. You should always be able to use a variable to order the data if needed.

## Bonus: slice variants

But, there are some useful variants on the `slice` function that help us select rows that have the maximum or minimum value of a particular variable:

```{r}
slice_max(mtcars, hp)
```

By default it just gives us one row, but we can ask for more than one by setting the `n` argument:

```{r}
slice_max(mtcars, hp, n=3)
```

We got 4 rows above because there was a tie at position 3. There's an option `with_ties` that can change how ties are handled.

There's also a minimum version:

```{r}
slice_min(mtcars, disp)
```

# Pipe: Chaining Commands Together

So, we can choose rows and choose columns separately; how do we combine these operations? `dplyr`, and other tidyverse, commands can be strung together is a series with a `%>%` (say/read: pipe) operator. If you are familiar with working in a terminal/at the command line, it works like a bash pipe character `|`. It takes the output of the command on the left and makes that the first input to the command on the right.

This works because the functions all take a data frame as the first input, and they return a data frame as the output.

We can rewrite

```{r}
select(police, date, time)
```

as

```{r}
police %>% select(date, time)
```

and you'll often see code formatted, so `%>%` is at the end of each line, and the following line that are still part of the same expression are indented:

```{r}
police %>%
  select(date, time)
```

The pipe comes from a package called `magrittr`, which has additional special operators in it that you can use. The keyboard shortcut for `%>%`is command-shift-M (Mac) or control-shift-M (Windows).

We can use the pipe to string together multiple commands operating on the same data frame:

```{r}
police %>%
  select(subject_race, subject_sex) %>%
  filter(subject_race == "white")
```

We would read the `%>%` in the command above as "then" if reading the code outloud: from police, select subject_race and subject_sex, then filter where subject_race is white.

This works because the dplyr functions take a tibble/data frame as the first argument (input) and return a tibble/data frame as the output. This makes it easy to pass a data frame through multiple operations, changing it one step at a time.

Order does matter, as the commands are executed in order. So this would give us an error:

```{r}
police %>%
  select(subject_sex, outcome) %>%
  filter(subject_race == "white")
```

Because `subject_race` is no longer in the data frame once we try to filter with it. We'd have to reverse the order:

```{r}
police %>%
  filter(subject_race == "white") %>%
  select(subject_sex, outcome)
```

You can use the pipe operator to string together commands outside of the tidyverse as well, and it works with any input and output, not just data frames:

```{r}
# sum(is.na(police$beat))
is.na(police$beat) %>% sum()
```

## EXERCISE

Select the date, time, and outcome (columns) of stops that occur in beat "71" (rows). Make use of the `%>%` operator.

The equivalent base R expression would be: `police[police$beat == "71", c("date", "time", "outcome")]`

Hint: remember that a column needs to still be in the data frame if you're going to use the column to filter.

```{r}
```

Note that so far, we haven't actually changed the `police` data frame at all. We've written expressions to give us output, but we haven't saved it.

Sometimes we may still want to save the result of some expression, such as after performing a bunch of data cleaning steps. We can assign the output of piped commands as we would with any other expression.

```{r}
police60201 <- police 
```

## EXERCISE

From the `police` data select only vehicle_year and vehicle_make columns for observations where there were contraband_weapons

```{r}

```

# Mutate: Change or Create Columns

`mutate()` is used to both change the values of an existing column and make a new column.

We name the column we're mutating and set the value. If the name already exists, it will update the column. If the name doesn't exist, it will create a new variable (column is appended at the end of existing columns).

```{r}
mutate(police, vehicle_age = 2017 - vehicle_year) %>%
  select(starts_with("vehicle"))  # just to pick a few columns to look at
```

We can put multiple mutations in the same call to mutate, with the expressions separated by commas:

```{r}
mutate(police, 
       vehicle_age = 2023 - vehicle_year,
       old_car = vehicle_year < 2000)
```

Within a call to mutate, we can refer to variables we made or changed earlier in the same call as well. Here, we create vehicle_age, and then use it to create vehicle_age_norm:

```{r}
police %>% 
  mutate(vehicle_age = 2023 - vehicle_year, 
         vehicle_age_norm = ifelse(vehicle_age < 0,  # ifelse test condition
                                   0,  # value if true
                                   vehicle_age)  # value if false
         ) %>%  
  # below is just making it easier for us to see what we changed
  select(starts_with("vehicle")) %>%
  filter(vehicle_age < 0)
```

Side note: there is a tidyverse version of `ifelse()` called `if_else()` that works generally the same except it is stricter about checking data types.

`mutate()` can also change an existing column. The location column in the data contains zip codes, that were read in as numeric values. This means the leading zero on some zip codes has been lost. Convert location to character data, and add back in the leading 0 if it should be there.

Here I'll change the location column twice in the same call with two different transformations:

```{r}
police %>%
  mutate(location = as.character(location),  # first convert to character, then recode below
         location = ifelse(nchar(location) == 4,  # ifelse test (vector of TRUE and FALSE)
                           paste0("0", location), # value if TRUE
                           location)) %>%  # value if FALSE
  select(location) %>%  # selecting just the column we mutated to look at
  filter(startsWith(location, "0"))  # selecting a few rows to look at the change
```

Remember that when using `mutate()`, you're operating on the entire column at once, so you can't select just a subset of the vector as you would with `[]`. This means more frequently using functions like `ifelse()` or helper functions such as `na_if()`, `replace_na()`, or `recode()`.

`na_if` replaces an existing value with `NA`. `replace_na` does roughly the opposite: replaces `NA` with a new value.

```{r}
mutate(police, vehicle_make = na_if(vehicle_make, "UNK"))
```

`na_if()` can only can check and replace one value at a time; it also can't be used with any expressions (`x <= 1`) -- only single values.

### EXERCISE

If beat is "/" or "CHICAGO", set it to `NA` instead using `mutate()`.

Hint: it's ok if you take two steps to do this.

```{r}

```

# BONUS!

If we have time, we will learn three additional dplyr functions: group_by, summarize, and arrange.

# Summarize

We'll start with `summarize()` (or `summarise()` - British spelling is accepted). We use `mutate()` when we want the output to have the same length as the input -- when we're operating on the individual elements in a vector - we want a value for every row in the data. When we want to condense multiple values down to a single (or a few values), such as taking the mean or standard deviation of a vector), we use summarize instead.

```{r}
police %>% 
  mutate(vehicle_age = 2017-vehicle_year) %>% # computing a new variable first
  summarize(mean_vehicle_age = mean(vehicle_age))
```

Note that even though there's just one value, we get a tibble returned. This is what to expect with the tidyverse.

As a side note, if we needed the single value (or a single vector), we could `pull()` it out of the tibble/data frame:

```{r}
police %>% 
  mutate(vehicle_age = 2017-vehicle_year) %>% # computing a new variable first
  summarize(mean_vehicle_age = mean(vehicle_age)) %>%
  pull()
```

We can compute more than one summary measure at the same time:

```{r}
police %>% 
  mutate(vehicle_age = 2017-vehicle_year) %>% # computing a new variable first
  summarize(mean_vehicle_age = mean(vehicle_age),
            sd_vehicle_age = sd(vehicle_age),
            min_date = min(date),
            max_date = max(date))
```

We get one column per summary variable we create. Once we group below, we'll see why we get the output in columns instead of rows.

## EXERCISE

Use summarize to compute the `min()` and `max()` `vehicle_year`

```{r}

```

## Across

If we want to apply the same summary functions to multiple columns in our data frame, we can write out all of the summary commands explicitly, or we can use `across()` to select which variables to summarize with which functions.

Let's use the `n_distinct()` function to count the number of distinct values in each column (`n_distinct(x)` is the same as `length(unique(x))`. This will help us see which columns don't have useful information because every value is the same.

`across()` selects columns using the helper functions you could give to `select()` directly. We'll use `everything()` here to select all columns.

```{r}
police %>%
  summarize(across(everything(), n_distinct))
```

If you wanted to select columns using their names, put them in a vector (so it's a single input argument):

```{r}
police %>%
  summarize(across(c(date, time, location, beat, subject_age), n_distinct))
```

If we want to apply multiple functions:

```{r}
police %>%
  summarize(across(!where(is.character), ## select columns that are not of type character
                   list(min, max)))   # take the min and max of each column
```

To fix the names in the output, explicitly name our summary functions in the list:

```{r}
police %>%
  summarize(across(!where(is.character), ## select columns that are not of type character
                   list(min_val=min, max_val=max)))   # take the min and max of each column
```

# Group By

With base R, when we want to compute summary measures or do other computation on groups in our data (as defined by some grouping variable), we use functions such as `tapply()` or `aggregate()`. With dplyr, we can explicitly group our tibble into subgroups. This isn't very useful by itself, but it is often combined with `summarize()` to compute summary measures by group.

First, what if we just group:

```{r}
police %>%
  group_by(outcome) # print this to the console
```

we see that it tells us that the tibble (data frame) is grouped by outcome, and that there are two groups. It doesn't rearrange the rows, it just keeps track of the groups for us.

Now, combine with summarize. But first, let's make the `vehicle_age` column we've been using actually part of the `police`dataset so that we don't have to keep creating it:

```{r}
police <- mutate(police, vehicle_age = 2023-vehicle_year)
```

Now, group and summarize:

```{r}
police %>% 
  group_by(subject_sex) %>%
  summarize(mean_vehicle_age = mean(vehicle_age),
            sd_vehicle_age = sd(vehicle_age))
```

Now we get one row for each group, and one column for each summary measure.

We can group by multiple columns, and we'll get all of the combinations of values present across the columns:

```{r}
police %>% 
  group_by(subject_sex, subject_race) %>%
  summarize(mean_vehicle_age = mean(vehicle_age),
            sd_vehicle_age = sd(vehicle_age))
```

Let's compute the ratio of warnings to citations by subject_race - note that we can use the variables we create in later expressions within the same call to `summarize()`:

```{r}
police %>%
  group_by(subject_race) %>%
  summarize(warnings = sum(outcome == "warning"),
            citations = sum(outcome == "citation"), 
            ratio = warnings/citations)
```

## EXERCISE

Compute the `min()` and `max()` `vehicle_year` for each `vehicle_make`.

```{r}

```

# Arrange

Finally, we come to `arrange()`, which is how we sort the rows in our data. We would mostly use this when viewing our data, but it's also useful when we need to compute a time series (lags and leads in the data), when we want to select just a few rows from each group, or any other order-sensitive transformations on our data.

```{r}
arrange(police, time)
```

To sort in reverse order, wrap the column name in `desc()`.

```{r}
arrange(police, desc(date))
```

Arrange by multiple columns, in order:

```{r}
arrange(police, date, desc(time))
```

An example where it matters: compute time between stops in the dataset:

```{r}
police %>%
  arrange(date, time) %>%
  mutate(datetime = lubridate::ymd_hms(paste(date, time)),  # combine to single value
         time_since_last = datetime - lag(datetime)) %>%  # current time - previous time
  select(datetime, time_since_last)
```

## EXERCISE

Sort the data by `vehicle_make` and then `vehicle_year`.

```{r}

```

## Count

A bonus function that I use frequently: `count()`. It's how you'd get output similar to `table()`

By itself, it counts the number of rows:

```{r}
police %>%
  count()
```

If you supply the name of a column, it makes a table:

```{r}
police %>%
  count(subject_sex)
```

This is the same result as if you grouped the data first:

```{r}
police %>%
  group_by(subject_sex) %>%
  count()
```

You can group by multiple columns directly with count:

```{r}
police %>%
  count(subject_sex, subject_race)
```

## EXERCISE

How many times does each type of violation appear in the dataset? Bonus: sort the results from most to least frequent. You can do this with `arrange()` or look at the documentation for `count()` to find another option.

```{r}

```
